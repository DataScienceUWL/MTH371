{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Exercise 3.52. \n",
    "\n",
    "Write code to implement the 1D derivative free optimization algorithm and use it to solve Exercise 3.48. Compare your answer to the analytic solution.\n",
    "\n",
    "Note: For 3.48 we need to find $0<x<10$ that minimizes $V(x) = x (20-2x)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_free_min(f, x0, dx):\n",
    "    \"\"\"\n",
    "    Find the approximate minimum of a function using derivative-free optimization.\n",
    "    This function performs a simple optimization by evaluating the function\n",
    "    at points to the left and right of the current position and moving in the\n",
    "    direction that decreases the function value. It stops when no further\n",
    "    improvement is found.\n",
    "    Parameters:\n",
    "    f (callable): The function to minimize. It should take a single argument (x) and return a scalar value.\n",
    "    x0 (float): The initial guess for the location of the minimum.\n",
    "    dx (float): The step size used to explore the function to the left and right of the current position.\n",
    "    Returns:\n",
    "    tuple: A tuple (current_x, current_f) where:\n",
    "        - current_x (float): The x-coordinate of the approximate minimum.\n",
    "        - current_f (float): The function value at the approximate minimum.\n",
    "\n",
    "    Notes:\n",
    "    - This method does not use derivatives, so it is suitable for functions\n",
    "        that are not differentiable or when derivatives are difficult to compute.\n",
    "    - The choice of `dx` affects the accuracy and speed of convergence.\n",
    "    - This method assumes the function has a single valley in the region of interest.\n",
    "    \"\"\"\n",
    "    current_x, current_f = x0, f(x0) # initial position and function value\n",
    "    fevals = 1\n",
    "    \n",
    "    while True:\n",
    "        # Calculate the new positions and function values\n",
    "        left_x, right_x = current_x - dx, current_x + dx\n",
    "        left_f, right_f = f(left_x), f(right_x)\n",
    "        fevals += 2\n",
    "        \n",
    "        if left_f < min(current_f, right_f): # f is smaller to the left so \"slide\" left\n",
    "            current_x, current_f = left_x, left_f\n",
    "        elif right_f < min(current_f, left_f): # f is smaller to the right so \"slide\" right\n",
    "            current_x, current_f = right_x, right_f\n",
    "        else: # neither left nor right is better, so we're done\n",
    "            break\n",
    "\n",
    "    print(f\"Approximate min at x = {current_x:.4f} with f = {current_f:.4f} after {fevals} evaluations.\")\n",
    "    \n",
    "    return current_x, current_f # return current x and f for the approximate minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate min at x = 3.3000 with f = -592.5480 after 29 evaluations.\n"
     ]
    }
   ],
   "source": [
    "# Note we're flipping the sign of the function to find the maximum\n",
    "V = lambda x: -x*(20-2*x)**2\n",
    "x0 = 2\n",
    "dx = 0.1\n",
    "x, Vx = deriv_free_min(V, x0, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_free_min_v2(f, x0, dx):\n",
    "    \"\"\"\n",
    "    Find the approximate minimum of a function using derivative-free optimization.\n",
    "    This function performs a simple optimization by evaluating the function\n",
    "    at points to the left and right of the current position and moving in the\n",
    "    direction that decreases the function value. It stops when no further\n",
    "    improvement is found.\n",
    "    Parameters:\n",
    "    f (callable): The function to minimize. It should take a single argument (x) and return a scalar value.\n",
    "    x0 (float): The initial guess for the location of the minimum.\n",
    "    dx (float): The step size used to explore the function to the left and right of the current position.\n",
    "    Returns:\n",
    "    tuple: A tuple (current_x, current_f) where:\n",
    "        - current_x (float): The x-coordinate of the approximate minimum.\n",
    "        - current_f (float): The function value at the approximate minimum.\n",
    "\n",
    "    Notes:\n",
    "    - This method does not use derivatives, so it is suitable for functions\n",
    "        that are not differentiable or when derivatives are difficult to compute.\n",
    "    - The choice of `dx` affects the accuracy and speed of convergence.\n",
    "    - This method assumes the function has a single valley in the region of interest.\n",
    "    \"\"\"\n",
    "\n",
    "    left_x, current_x, right_x = x0 - dx, x0, x0 + dx # initial positions\n",
    "    left_f, current_f, right_f = f(left_x), f(current_x), f(right_x) # initial function values \n",
    "    fevals = 3\n",
    "    \n",
    "    while True:\n",
    "        if left_f < min(current_f, right_f): # f is smaller to the left so \"slide\" left\n",
    "            current_x, current_f, right_x, right_f = left_x, left_f, current_x, current_f\n",
    "            left_x = current_x - dx\n",
    "            left_f = f(left_x)\n",
    "            fevals += 1\n",
    "        elif right_f < min(current_f, left_f): # f is smaller to the right so \"slide\" right\n",
    "            current_x, current_f, left_x, left_f = right_x, right_f, current_x, current_f\n",
    "            right_x = current_x + dx\n",
    "            right_f = f(right_x)\n",
    "            fevals += 1\n",
    "        else: # neither left nor right is better, so we're done\n",
    "            break\n",
    "    \n",
    "    print(f\"Approximate min at x = {current_x:.4f} with f = {current_f:.4f} after {fevals} evaluations.\")\n",
    "    \n",
    "    return current_x, current_f # return current x and f for the approximate minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate min at x = 3.3000 with f = -592.5480 after 16 evaluations.\n"
     ]
    }
   ],
   "source": [
    "# Note we're flipping the sign of the function to find the maximum\n",
    "V = lambda x: -x*(20-2*x)**2\n",
    "x0 = 2\n",
    "dx = 0.1\n",
    "x, Vx = deriv_free_min_v2(V, x0, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_free_min_adapt_dx(f, x0, dx, dx_min=1e-6):\n",
    "    \"\"\"\n",
    "    Find the approximate minimum of a function using derivative-free optimization with adaptive step size.\n",
    "    \n",
    "    This method evaluates the function at points to the left and right of the current position \n",
    "    and moves in the direction that decreases the function value. If no improvement is found, \n",
    "    the step size is halved until it reaches a minimum threshold (dx_min).\n",
    "    \n",
    "    Parameters:\n",
    "    f (callable): The function to minimize. It should take a single argument (x) and return a scalar value.\n",
    "    x0 (float): The initial guess for the location of the minimum.\n",
    "    dx (float): The initial step size used to explore the function to the left and right of the current position.\n",
    "    dx_min (float): The minimum allowable step size. Default is 1e-6.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple (current_x, current_f) where:\n",
    "        - current_x (float): The x-coordinate of the approximate minimum.\n",
    "        - current_f (float): The function value at the approximate minimum.\n",
    "    \n",
    "    Notes:\n",
    "    - This method does not use derivatives, so it is suitable for functions that are not differentiable \n",
    "      or when derivatives are difficult to compute.\n",
    "    - The choice of `dx` affects the accuracy and speed of convergence.\n",
    "    - This method assumes the function has a single valley in the region of interest.\n",
    "    \"\"\"\n",
    "\n",
    "    left_x, current_x, right_x = x0 - dx, x0, x0 + dx # initial positions\n",
    "    left_f, current_f, right_f = f(left_x), f(current_x), f(right_x) # initial function values \n",
    "    fevals = 3\n",
    "    \n",
    "    while True:\n",
    "        if left_f < min(current_f, right_f): # f is smaller to the left so \"slide\" left\n",
    "            current_x, current_f, right_x, right_f = left_x, left_f, current_x, current_f\n",
    "            left_x = current_x - dx\n",
    "            left_f = f(left_x)\n",
    "            fevals += 1\n",
    "        elif right_f < min(current_f, left_f): # f is smaller to the right so \"slide\" right\n",
    "            current_x, current_f, left_x, left_f = right_x, right_f, current_x, current_f\n",
    "            right_x = current_x + dx\n",
    "            right_f = f(right_x)\n",
    "            fevals += 1\n",
    "        else:\n",
    "            if dx < dx_min:  # Stop if the step size is below the minimum threshold\n",
    "                break\n",
    "            dx = dx / 2  # reduce the step size by half\n",
    "            left_x, right_x = current_x - dx, current_x + dx # update the new positions\n",
    "            left_f, right_f = f(left_x), f(right_x) # update the new function values\n",
    "            fevals += 2\n",
    "    \n",
    "    print(f\"Approximate min at x = {current_x:.4f} with f = {current_f:.4f} after {fevals} evaluations.\")\n",
    "\n",
    "    return current_x, current_f # return current x and f for the approximate minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate min at x = 3.3333 with f = -592.5926 after 46 evaluations.\n"
     ]
    }
   ],
   "source": [
    "# Note we're flipping the sign of the function to find the maximum\n",
    "V = lambda x: -x*(20-2*x)**2\n",
    "x0 = 2\n",
    "dx = 0.1\n",
    "x, Vx = deriv_free_min_adapt_dx(V, x0, dx, dx_min= 1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS776v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
